{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Craw Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tạo danh sách url dẫn đến danh sách thẻ bài đăng**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi tìm kiếm các bài đăng bán BDS ở TP. HCM, ta sẽ nhận được danh sách kết quả chứa theo thẻ. Mỗi thẻ chứa định những thông tin cơ bản về BDS như giá, diện tích, ngày đăng, đường dẫn đến bài đăng chi tiết. \\\n",
    "Kết quả tìm kiếm trả về dưới dạng page. Có tổng cộng 604 page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = ['https://batdongsan.vn/ban-nha-dat-ho-chi-minh']\n",
    "for i in range(2, 604):\n",
    "    url_list.append('https://batdongsan.vn/ban-nha-dat-ho-chi-minh/p' + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sử dụng thư viện Selenium trích xuất các thông tin cơ bản**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để cài đặt selenium cho Google Colab, sử dụng địa chị này: https://medium.com/@MinatoNamikaze02/running-selenium-on-google-colab-a118d10ca5f8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup when run on colab\n",
    "%%shell\n",
    "sudo apt -y update\n",
    "sudo apt install -y wget curl unzip\n",
    "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
    "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
    "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
    "dpkg -i google-chrome-stable_current_amd64.deb\n",
    "\n",
    "wget -N https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip -P /tmp/\n",
    "unzip -o /tmp/chromedriver-linux64.zip -d /tmp/\n",
    "chmod +x /tmp/chromedriver-linux64/chromedriver\n",
    "mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver\n",
    "pip install selenium chromedriver_autoinstaller\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "\n",
    "from selenium import webdriver\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless') # this is must\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chromedriver_autoinstaller.install()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(driver, url):\n",
    "    raw_data = pd.DataFrame(columns=['title', 'price', 'area', 'time', 'page_link'])\n",
    "    driver.get(url)\n",
    "    list = driver.find_elements(By.XPATH, \"//div[@class='uk-grid uk-grid-small uk-grid-width-1-1']/div\")\n",
    "\n",
    "    for item in list:\n",
    "        title = item.find_element(By.XPATH, \".//div[@class='name']\").text\n",
    "        # Get page link\n",
    "        page_link = item.find_element(By.XPATH, \".//div[@class='name']/a\").get_attribute('href')\n",
    "\n",
    "        # Get price, if it doesn't exist, set it to Null\n",
    "        try:\n",
    "            price = item.find_element(By.XPATH, \".//span[@class='price']\").text\n",
    "        except:\n",
    "            price = None\n",
    "\n",
    "        # Get area, if it doesn't exist, set it to Null\n",
    "        try:\n",
    "            area = item.find_element(By.XPATH, \".//span[@class='acreage']\").text\n",
    "        except:\n",
    "            area = None\n",
    "\n",
    "        # Get time, if it doesn't exist, set it to Null\n",
    "        try:\n",
    "            time = item.find_element(By.XPATH, \".//time[@class='timeago']\").get_attribute('datetime')\n",
    "        except:\n",
    "            time = None\n",
    "        raw_data = raw_data._append({'title': title, 'price': price, 'area': area, 'time': time, 'page_link': page_link}, ignore_index=True)\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create empty dataframe \n",
    "raw_data = pd.DataFrame(columns=['title', 'price', 'area', 'time', 'page_link'])\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "# If running on Colab, uncomment the following line\n",
    "#driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "for url in url_list:\n",
    "    raw_data = raw_data._append(get_data(driver, url), ignore_index=True)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to csv file\n",
    "raw_data.to_csv('raw_data.csv', index=False)\n",
    "\n",
    "# Save file to Google Drive when running on Colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#raw_data.to_csv('/content/drive/My Drive/raw_data_p201_p604.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>time</th>\n",
       "      <th>page_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chưa tới 30tr/m2 - Hàng ngộp bank BAO ĐẦU TƯ ...</td>\n",
       "      <td>3899000000 tỷ</td>\n",
       "      <td>150m2</td>\n",
       "      <td>2023-12-10 17:11:02</td>\n",
       "      <td>https://batdongsan.vn/chua-toi-30trm2-hang-ngo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bán nhà HXH Âu Cơ Phường 9 Tân Bình, 51m2 3 Tầ...</td>\n",
       "      <td>5.5 tỷ</td>\n",
       "      <td>51m2</td>\n",
       "      <td>2023-12-10 18:40:26</td>\n",
       "      <td>https://batdongsan.vn/ban-nha-hxh-au-co-phuong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SÁT MẶT TIỀN PHAN ĐĂNG LƯU, PHƯỜNG 7, PHÚ NHUẬ...</td>\n",
       "      <td>4.6 tỷ</td>\n",
       "      <td>45m2</td>\n",
       "      <td>2023-12-10 18:56:17</td>\n",
       "      <td>https://batdongsan.vn/sat-mat-tien-phan-dang-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHỦ GẤP BÁN TRƯỚC TẾT LÊ HỒNG PHONG QUẬN 5 RA ...</td>\n",
       "      <td>7.35 tỷ</td>\n",
       "      <td>41m2</td>\n",
       "      <td>2023-12-10 20:49:28</td>\n",
       "      <td>https://batdongsan.vn/chu-gap-ban-truoc-tet-le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LŨY BÁN BÍCH,TÂN PHÚ-DIỆN TÍCH KHỦNG 96M2 ( 4....</td>\n",
       "      <td>Thỏa thuận</td>\n",
       "      <td>96m2</td>\n",
       "      <td>2023-12-07 14:13:40</td>\n",
       "      <td>https://batdongsan.vn/luy-ban-bichtan-phu-dien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          price   area  \\\n",
       "0  Chưa tới 30tr/m2 - Hàng ngộp bank BAO ĐẦU TƯ ...  3899000000 tỷ  150m2   \n",
       "1  Bán nhà HXH Âu Cơ Phường 9 Tân Bình, 51m2 3 Tầ...         5.5 tỷ   51m2   \n",
       "2  SÁT MẶT TIỀN PHAN ĐĂNG LƯU, PHƯỜNG 7, PHÚ NHUẬ...         4.6 tỷ   45m2   \n",
       "3  CHỦ GẤP BÁN TRƯỚC TẾT LÊ HỒNG PHONG QUẬN 5 RA ...        7.35 tỷ   41m2   \n",
       "4  LŨY BÁN BÍCH,TÂN PHÚ-DIỆN TÍCH KHỦNG 96M2 ( 4....     Thỏa thuận   96m2   \n",
       "\n",
       "                  time                                          page_link  \n",
       "0  2023-12-10 17:11:02  https://batdongsan.vn/chua-toi-30trm2-hang-ngo...  \n",
       "1  2023-12-10 18:40:26  https://batdongsan.vn/ban-nha-hxh-au-co-phuong...  \n",
       "2  2023-12-10 18:56:17  https://batdongsan.vn/sat-mat-tien-phan-dang-l...  \n",
       "3  2023-12-10 20:49:28  https://batdongsan.vn/chu-gap-ban-truoc-tet-le...  \n",
       "4  2023-12-07 14:13:40  https://batdongsan.vn/luy-ban-bichtan-phu-dien...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả được lưu ở đường dẫn sau: https://raw.githubusercontent.com/KhiemDangLe/Final-Project/main/grid_list_raw_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuy nhiên, thư viện Selenium tiêu tốn tài nguyên hơn và thời gian chạy lâu hơn so với sử dụng thư viện request và bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Lấy dữ liệu từ các bài đăng chi tiết**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_data = pd.read_csv('https://raw.githubusercontent.com/KhiemDangLe/Final-Project/main/grid_list_raw_data.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>time</th>\n",
       "      <th>page_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chưa tới 30tr/m2 - Hàng ngộp bank BAO ĐẦU TƯ ...</td>\n",
       "      <td>3899000000 tỷ</td>\n",
       "      <td>150m2</td>\n",
       "      <td>2023-12-10 17:11:02</td>\n",
       "      <td>https://batdongsan.vn/chua-toi-30trm2-hang-ngo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bán nhà HXH Âu Cơ Phường 9 Tân Bình, 51m2 3 Tầ...</td>\n",
       "      <td>5.5 tỷ</td>\n",
       "      <td>51m2</td>\n",
       "      <td>2023-12-10 18:40:26</td>\n",
       "      <td>https://batdongsan.vn/ban-nha-hxh-au-co-phuong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SÁT MẶT TIỀN PHAN ĐĂNG LƯU, PHƯỜNG 7, PHÚ NHUẬ...</td>\n",
       "      <td>4.6 tỷ</td>\n",
       "      <td>45m2</td>\n",
       "      <td>2023-12-10 18:56:17</td>\n",
       "      <td>https://batdongsan.vn/sat-mat-tien-phan-dang-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHỦ GẤP BÁN TRƯỚC TẾT LÊ HỒNG PHONG QUẬN 5 RA ...</td>\n",
       "      <td>7.35 tỷ</td>\n",
       "      <td>41m2</td>\n",
       "      <td>2023-12-10 20:49:28</td>\n",
       "      <td>https://batdongsan.vn/chu-gap-ban-truoc-tet-le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LŨY BÁN BÍCH,TÂN PHÚ-DIỆN TÍCH KHỦNG 96M2 ( 4....</td>\n",
       "      <td>Thỏa thuận</td>\n",
       "      <td>96m2</td>\n",
       "      <td>2023-12-07 14:13:40</td>\n",
       "      <td>https://batdongsan.vn/luy-ban-bichtan-phu-dien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          price   area  \\\n",
       "0  Chưa tới 30tr/m2 - Hàng ngộp bank BAO ĐẦU TƯ ...  3899000000 tỷ  150m2   \n",
       "1  Bán nhà HXH Âu Cơ Phường 9 Tân Bình, 51m2 3 Tầ...         5.5 tỷ   51m2   \n",
       "2  SÁT MẶT TIỀN PHAN ĐĂNG LƯU, PHƯỜNG 7, PHÚ NHUẬ...         4.6 tỷ   45m2   \n",
       "3  CHỦ GẤP BÁN TRƯỚC TẾT LÊ HỒNG PHONG QUẬN 5 RA ...        7.35 tỷ   41m2   \n",
       "4  LŨY BÁN BÍCH,TÂN PHÚ-DIỆN TÍCH KHỦNG 96M2 ( 4....     Thỏa thuận   96m2   \n",
       "\n",
       "                  time                                          page_link  \n",
       "0  2023-12-10 17:11:02  https://batdongsan.vn/chua-toi-30trm2-hang-ngo...  \n",
       "1  2023-12-10 18:40:26  https://batdongsan.vn/ban-nha-hxh-au-co-phuong...  \n",
       "2  2023-12-10 18:56:17  https://batdongsan.vn/sat-mat-tien-phan-dang-l...  \n",
       "3  2023-12-10 20:49:28  https://batdongsan.vn/chu-gap-ban-truoc-tet-le...  \n",
       "4  2023-12-07 14:13:40  https://batdongsan.vn/luy-ban-bichtan-phu-dien...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một trong những nguyên nhân làm chậm quá trình lấy dữ liêu khi sử dụng BS4 là tốc độ parsing. Để tối ưu, theo hướng dẫn từ documentation của BS4 ta sẽ sử dụng 2 thư viện là lxml và cchardet. Đồng thời, chúng ta sẽ sử dụng dụng đa luồng đẻ tăng tốc độ craw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\likgn\\onedrive - vnu-hcmus\\qua trinh hoc tap\\nam2\\kiii\\th_nmkhdl\\final-project-dsk22\\.venv\\lib\\site-packages (5.2.2)\n",
      "Collecting pyproject-toml\n",
      "  Downloading pyproject_toml-0.0.10-py3-none-any.whl.metadata (642 bytes)\n",
      "Requirement already satisfied: setuptools>=42 in c:\\users\\likgn\\onedrive - vnu-hcmus\\qua trinh hoc tap\\nam2\\kiii\\th_nmkhdl\\final-project-dsk22\\.venv\\lib\\site-packages (from pyproject-toml) (65.5.0)\n",
      "Collecting wheel (from pyproject-toml)\n",
      "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting toml (from pyproject-toml)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jsonschema (from pyproject-toml)\n",
      "  Downloading jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\likgn\\onedrive - vnu-hcmus\\qua trinh hoc tap\\nam2\\kiii\\th_nmkhdl\\final-project-dsk22\\.venv\\lib\\site-packages (from jsonschema->pyproject-toml) (23.2.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->pyproject-toml)\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->pyproject-toml)\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->pyproject-toml)\n",
      "  Downloading rpds_py-0.18.1-cp311-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Downloading pyproject_toml-0.0.10-py3-none-any.whl (6.9 kB)\n",
      "Downloading jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "   ---------------------------------------- 0.0/88.3 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 41.0/88.3 kB 991.0 kB/s eta 0:00:01\n",
      "   ------------------ --------------------- 41.0/88.3 kB 991.0 kB/s eta 0:00:01\n",
      "   ------------------ --------------------- 41.0/88.3 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 88.3/88.3 kB 500.5 kB/s eta 0:00:00\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.18.1-cp311-none-win_amd64.whl (209 kB)\n",
      "   ---------------------------------------- 0.0/209.0 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 92.2/209.0 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 209.0/209.0 kB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: wheel, toml, rpds-py, referencing, jsonschema-specifications, jsonschema, pyproject-toml\n",
      "Successfully installed jsonschema-4.22.0 jsonschema-specifications-2023.12.1 pyproject-toml-0.0.10 referencing-0.35.1 rpds-py-0.18.1 toml-0.10.2 wheel-0.43.0\n",
      "Collecting cchardet\n",
      "  Using cached cchardet-2.1.7.tar.gz (653 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: cchardet\n",
      "  Building wheel for cchardet (setup.py): started\n",
      "  Building wheel for cchardet (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for cchardet\n",
      "Failed to build cchardet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [22 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-cpython-311\n",
      "      creating build\\lib.win-amd64-cpython-311\\cchardet\n",
      "      copying src\\cchardet\\version.py -> build\\lib.win-amd64-cpython-311\\cchardet\n",
      "      copying src\\cchardet\\__init__.py -> build\\lib.win-amd64-cpython-311\\cchardet\n",
      "      running build_ext\n",
      "      building 'cchardet._cchardet' extension\n",
      "      creating build\\temp.win-amd64-cpython-311\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\src\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\src\\cchardet\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\src\\ext\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\src\\ext\\uchardet\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\src\\ext\\uchardet\\src\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\src\\ext\\uchardet\\src\\LangModels\n",
      "      \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.39.33519\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -Isrc/ext/uchardet/src \"-Ic:\\Users\\likgn\\OneDrive - VNU-HCMUS\\Qua Trinh Hoc Tap\\Nam2\\KiII\\TH_NMKHDL\\Final-Project-DSK22\\.venv\\include\" \"-IC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\include\" \"-IC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.39.33519\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.39.33519\\ATLMFC\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /EHsc /Tpsrc/cchardet\\_cchardet.cpp /Fobuild\\temp.win-amd64-cpython-311\\Release\\src/cchardet\\_cchardet.obj\n",
      "      _cchardet.cpp\n",
      "      src/cchardet\\_cchardet.cpp(196): fatal error C1083: Cannot open include file: 'longintrepr.h': No such file or directory\n",
      "      error: command 'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.39.33519\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for cchardet\n",
      "ERROR: Could not build wheels for cchardet, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install lxml\n",
    "!pip install pyproject-toml\n",
    "!pip install cython\n",
    "!pip install cchardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import cchardet\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def get_detail_data(url_list):\n",
    "    raw_detail_data = pd.DataFrame(columns=['page_link', 'category', 'district', 'article_id', 'bedrom', 'wc', 'direction', 'balcony_direction', 'description'])\n",
    "    loop = 0\n",
    "    for url in url_list:\n",
    "        print(loop)\n",
    "        loop += 1\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'lxml')\n",
    "\n",
    "        #header\n",
    "        try:\n",
    "            header = soup.find('ul', class_ = 'uk-breadcrumb').find_all('li')\n",
    "            category = header[1].text[4:]\n",
    "            district = header[3].text\n",
    "        except:\n",
    "            category = None\n",
    "            district = None\n",
    "\n",
    "        #panel\n",
    "        try:\n",
    "            panel = soup.find('div', class_ = 'landtech-container').find('div', class_ = 'uk-panel').get_text()\n",
    "        except:\n",
    "            panel = None\n",
    "        try:\n",
    "            bedroom = re.search('(\\d+) PN', panel).group(1)\n",
    "        except:\n",
    "            bedroom = None\n",
    "        try:    \n",
    "            wc = re.search('(\\d+) WC', panel).group(1)\n",
    "        except:\n",
    "            wc = None\n",
    "        try:\n",
    "            direction = re.search('Hướng nhà:\\s([^\\s]+)', panel).group(1)\n",
    "        except:\n",
    "            direction = None\n",
    "        try:\n",
    "            balcony_direction = re.search('Hướng ban công:\\s([^\\s]+)', panel).group(1)\n",
    "        except:\n",
    "            balcony_direction = None\n",
    "        try:\n",
    "            article_id = re.search('Mã tin:\\s([^\\s]+)', panel).group(1)\n",
    "        except:\n",
    "            article_id = None\n",
    "        try:\n",
    "            description = soup.find_all('div', class_= 'landtech-container')[1].find('div', class_ = 'content').get_text()\n",
    "            description = re.sub('[\\n \\r \\+\\-#,.]+', ' ', description)\n",
    "        except:\n",
    "            description = None\n",
    "        raw_detail_data = raw_detail_data._append({'page_link': url, 'category': category, 'district': district, 'article_id': article_id, 'bedrom': bedroom, 'wc': wc, 'direction': direction, 'balcony_direction': balcony_direction, 'description': description}, ignore_index=True)\n",
    "    return raw_detail_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to csv file\n",
    "raw_detail_data.to_csv('raw_detail_data.csv', index=False)\n",
    "\n",
    "# Save file to Google Drive when running on Colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#raw_data.to_csv('/content/drive/My Drive/raw_data_p201_p604.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('raw_detail_data.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong lúc thực hiện project, vì thời gian chạy thực lấy dữ liệu rất lâu. Do đó, để tránh chạy lại từ đầu khi gặp các vấn đề phát sinh, ta có thể chia thành nhiều lần chạy.\\\n",
    "```python\n",
    "raw_detail_data = get_detail_data(raw_data['page_link'][:3000])\n",
    "#Save to file\n",
    "raw_detail_data = get_detail_data(raw_data['page_link'][3001:6000])\n",
    "#Save to file\n",
    "raw_detail_data = get_detail_data(raw_data['page_link'][6001:9000])\n",
    "#Save to file\n",
    "raw_detail_data = get_detail_data(raw_data['page_link'][9000:])\n",
    "#Save to file\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Update**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import cchardet\n",
    "import re\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "\n",
    "def get_detail_data(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'lxml')\n",
    "\n",
    "    # header\n",
    "    try:\n",
    "        header = soup.find('ul', class_='uk-breadcrumb').find_all('li')\n",
    "        category = header[1].text[4:]\n",
    "        district = header[3].text\n",
    "    except:\n",
    "        category = None\n",
    "        district = None\n",
    "\n",
    "    # panel\n",
    "    try:\n",
    "        panel = soup.find('div', class_='landtech-container').find('div', class_='uk-panel')\n",
    "        title = panel.find('h1', class_='uk-panel-title').get_text()\n",
    "        price = panel.find('strong', class_='price').get_text()\n",
    "        price = re.sub('[\\n\\t]+', '', price)\n",
    "        # price unit: Nghìn, Triệu, Tỷ, Nghìn/m2, Triệu/m2, Tỷ/m2\n",
    "        date_posted = panel.find('time', class_='timeago').get('datetime')\n",
    "        date_posted = re.search('(\\d{4}-\\d{2}-\\d{2})', date_posted).group(1)\n",
    "        panel = panel.get_text()\n",
    "    except:\n",
    "        panel = None\n",
    "\n",
    "    try:\n",
    "        area = re.search('(\\d+) m2', panel).group(1)\n",
    "    except:\n",
    "        area = None\n",
    "    try:\n",
    "        bedroom = re.search('(\\d+) PN', panel).group(1)\n",
    "    except:\n",
    "        bedroom = None\n",
    "    try:\n",
    "        wc = re.search('(\\d+) WC', panel).group(1)\n",
    "    except:\n",
    "        wc = None\n",
    "    try:\n",
    "        direction = re.search('Hướng nhà:\\s([^\\s]+)', panel).group(1)\n",
    "    except:\n",
    "        direction = None\n",
    "    try:\n",
    "        balcony_direction = re.search('Hướng ban công:\\s([^\\s]+)', panel).group(1)\n",
    "    except:\n",
    "        balcony_direction = None\n",
    "    try:\n",
    "        article_id = re.search('Mã tin:\\s([^\\s]+)', panel).group(1)\n",
    "    except:\n",
    "        article_id = None\n",
    "    try:\n",
    "      description = soup.find_all('div', class_='landtech-container')[1].find('div', class_='content').get_text()\n",
    "      description = re.sub('[\\n \\t \\r \\+\\-#,]+', ' ', description)\n",
    "    except:\n",
    "      description = None\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        'page_link': url,\n",
    "        'title': title,\n",
    "        'article_id': article_id,\n",
    "        'category': category,\n",
    "        'district': district,\n",
    "        'date_posted': date_posted,\n",
    "        'price': price,\n",
    "        'area': area,\n",
    "        'bedrom': bedroom,\n",
    "        'wc': wc,\n",
    "        'direction': direction,\n",
    "        'balcony_direction': balcony_direction,\n",
    "        'description': description\n",
    "    }])\n",
    "\n",
    "def parallel_get_detail_data(url_list):\n",
    "    with mp.Pool(processes=20) as pool:\n",
    "        results = pool.map(get_detail_data, url_list)\n",
    "    return pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "raw_detail_data = pd.DataFrame(columns=['page_link', 'article_id', 'title', 'category', 'district', 'date_posted', 'price', 'area', 'bedrom', 'wc', 'direction', 'balcony_direction', 'description'])\n",
    "raw_detail_data = parallel_get_detail_data(raw_data['page_link'][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_detail_data.to_csv('raw_detail_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
